{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Classification Training Pipeline\n",
    "\n",
    "In this sample, image preprocessing is on cpu nodes while training on distributed gpu nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from azureml.core import Workspace\n",
    "from azureml.core.compute import AmlCompute, ComputeTarget\n",
    "from azureml.pipeline.wrapper import Module, Pipeline, dsl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure workspace and compute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "WARNING - Warning: Falling back to use azure cli login credentials.\nIf you run your code in unattended mode, i.e., where you can't give a user input, then we recommend to use ServicePrincipalAuthentication or MsiAuthentication.\nPlease refer to aka.ms/aml-notebook-auth for different authentication mechanisms in azureml-sdk.\nitp-pilot\nitp-pilot-ResGrp\nwesteurope\n4aaa645c-5ae2-4ae9-a17a-84b9023bc56a\n"
    }
   ],
   "source": [
    "# configure workspace information here.\n",
    "workspace = Workspace.get(\n",
    "    name='itp-pilot',\n",
    "    subscription_id='4aaa645c-5ae2-4ae9-a17a-84b9023bc56a',\n",
    "    resource_group='itp-pilot-ResGrp'\n",
    ")\n",
    "print(workspace.name, workspace.resource_group, workspace.location, workspace.subscription_id, sep = '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Found existing gpu compute target: k80-16-a\n"
    }
   ],
   "source": [
    "# specify ITP compute name.\n",
    "gpu_compute_target = 'k80-16-a'\n",
    "gpu_compute = ComputeTarget(workspace, gpu_compute_target)\n",
    "print(\"Found existing gpu compute target: {}\".format(gpu_compute_target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare dataset\n",
    "This smaller imagenet dataset is a subset of the official one.\n",
    "- training dataset contains 9100 images (7 categories * 1300 images per category)\n",
    "- validation dataset contains 350 images (7 categories * 50 images per category)\n",
    "\n",
    "Need to use zip file here to avoid perf issue of mounting file dataset with many subfolders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dataset\n",
    "from azureml.core.dataset import Dataset\n",
    "\n",
    "train_image_dataset = Dataset.get_by_name(workspace, name='ImageNetSmallerTrainData')\n",
    "val_image_dataset = Dataset.get_by_name(workspace, name='ImageNetSmallerValidData')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load built-in modules\n",
    "convert_func = Module.load(workspace, namespace='azureml', name='Convert to Image Directory')\n",
    "init_transform_func = Module.load(workspace, namespace='azureml', name='Init Image Transformation')\n",
    "apply_transform_func = Module.load(workspace, namespace='azureml', name='Apply Image Transformation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load local modules\n",
    "# this train module is a mpi module.\n",
    "module_folder = r'./modules'\n",
    "yaml_file_name = 'entry.spec.yaml'\n",
    "train_module = Module.from_yaml(workspace, yaml_file=f'{module_folder}/ConvNets/{yaml_file_name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up a pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define pipeline\n",
    "@dsl.pipeline(name='image classification', description='image classification', default_compute_target='k80-16-a')\n",
    "def generated_pipeline():\n",
    "    convert_train = convert_func(\n",
    "        input_dataset=train_image_dataset\n",
    "    )\n",
    "    \n",
    "    convert_val = convert_func(\n",
    "        input_dataset=val_image_dataset\n",
    "    )\n",
    "    \n",
    "    init_trans = init_transform_func(\n",
    "        resize='False',\n",
    "        size=256,\n",
    "        center_crop='False',\n",
    "        crop_size=224,\n",
    "        pad='False',\n",
    "        padding=0,\n",
    "        color_jitter='False',\n",
    "        grayscale='False',\n",
    "        random_resized_crop='False',\n",
    "        random_resized_crop_size=256,\n",
    "        random_crop='False',\n",
    "        random_crop_size=224,\n",
    "        random_horizontal_flip='True',\n",
    "        random_vertical_flip='False',\n",
    "        random_rotation='False',\n",
    "        random_rotation_degrees=0,\n",
    "        random_affine='False',\n",
    "        random_affine_degrees=0,\n",
    "        random_grayscale='False',\n",
    "        random_perspective='False'\n",
    "    )\n",
    "    \n",
    "    apply_trans_on_train = apply_transform_func(\n",
    "        mode='For training',\n",
    "        input_image_transformation=init_trans.outputs.output_image_transformation,\n",
    "        input_image_directory=convert_train.outputs.output_image_directory\n",
    "    )\n",
    "    \n",
    "    apply_trans_on_val = apply_transform_func(\n",
    "        mode='For inference',\n",
    "        input_image_transformation=init_trans.outputs.output_image_transformation,\n",
    "        input_image_directory=convert_val.outputs.output_image_directory\n",
    "    )\n",
    "    \n",
    "    train = train_module(\n",
    "        train_data=apply_trans_on_train.outputs.output_image_directory,\n",
    "        valid_data=apply_trans_on_val.outputs.output_image_directory,\n",
    "        data_backend='pytorch',\n",
    "        pretrained_weights=None,\n",
    "        epochs=4,\n",
    "        seed=123,\n",
    "        batch_size=16,\n",
    "        save_checkpoint_epochs=2\n",
    "    )\n",
    "    # perform distributed training with 2 nodes.\n",
    "    # note: process_count_per_node should be 1 because this module will launch distributed processes based on node device count.\n",
    "    train.runsettings.configure(target=gpu_compute_target, node_count=2, process_count_per_node=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a pipeline\n",
    "pipeline = generated_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "k80-16-a not found in workspace, assume this is an AmlCompute\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "try {\n    require.undef(\"validate_widget\")\n\n    define('validate_widget', [\"@jupyter-widgets/base\"], function(widgets) {\n        var ValidateView = widgets.DOMWidgetView.extend({\n            render () {\n                window.widget_self = this\n                var visualize_id = this.model.get('visualize_id')\n\n                if (!window._renderLock) {\n                    window._renderLock = {}\n                }\n                if (window._renderLock[visualize_id]) {\n                    return\n                }\n                window._renderLock[visualize_id] = \"widget\"\n                console.log(\"load as widget\", Date.now())\n\n                var lib_url = this.model.get('lib_url')\n                var graph_json = JSON.parse(this.model.get('graph_json'))\n                var env_json = JSON.parse(this.model.get('env_json'))\n                var container_id = this.model.get('container_id')\n\n                window.render_container_id = container_id\n                window.graph_json = graph_json\n                window.env_json = env_json\n                window.before_script = performance.now()\n\n                var container = document.createElement('div')\n                container.id = container_id\n                this.el.appendChild(container)\n\n                var style = document.createElement('style')\n                style.innerHTML = [\n                    \"#\", container_id, \" svg.react-dag-editor-svg-container { height: 800px; }\",\n                    \".cell-output-ipywidget-background { background: transparent !important }\"\n                ].join('')\n                this.el.appendChild(style)\n\n                this.model.on('msg:custom', dispatchMessage, this);\n\n                if (!window.__event_hub) {\n                    window.__event_hub = {}\n                }\n                if (!window.__event_hub[container_id]) {\n                    window.__event_hub[container_id] = {}\n                }\n\n                if (!window.__send_event) {\n                    window.__send_event = {}\n                }\n                window.__send_event[container_id] = sendMessage.bind(this)\n\n                function sendMessage(message, uid, content) {\n                    return new Promise((resolve) => {\n                        this.model.send({\n                            message: `${message}:request`,\n                            body: {\n                                uid,\n                                content\n                            }\n                        })\n    \n                        var respMessageKey = `${message}:response`\n                        if (!window.__event_hub[container_id][respMessageKey]) {\n                            window.__event_hub[container_id][respMessageKey] = []\n                        }\n                        window.__event_hub[container_id][respMessageKey].push(callback)\n    \n                        function callback (response) {\n                            if (response.uid !== uid) {\n                                return\n                            }\n\n                            var idx = window.__event_hub[container_id][respMessageKey].indexOf(callback) \n                            window.__event_hub[container_id][respMessageKey].splice(idx, 1)\n                            \n                            resolve(response)\n                        }\n                    })\n                }\n\n                function dispatchMessage (rawMessage) {\n                    var message = rawMessage.message\n                    var body = rawMessage.body\n\n                    if (!window.__event_hub[container_id][message]) {\n                        window.__event_hub[container_id][message] = []\n                    }\n                    var listeners = window.__event_hub[container_id][message]\n\n                    listeners.forEach(cb => {\n                        try {\n                            cb(body)\n                        } catch (e) {\n                            console.error(\"Unexpected error in listener\", e)\n                        }\n                    })\n\n                    console.log(body)\n                }\n\n                var script = document.createElement('script')\n                script.src = lib_url\n                this.el.appendChild(script)\n            }\n        });\n\n        return {\n            ValidateView\n        }\n    })\n} catch (e) {\n    console.log(\"create validation widget failed\", e)\n}"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "ValidateView(container_id='container_id_5aab9138-7de0-4dfe-a0b8-619709e031d0_widget', env_json='{\"subscription…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "04ebfccf4c9e4815a0bddd94dd139baa"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n        <style>\n        #container_id_5aab9138-7de0-4dfe-a0b8-619709e031d0_script svg.react-dag-editor-svg-container {\n            height: 800px;\n        }\n        </style>\n        <div id=\"container_id_5aab9138-7de0-4dfe-a0b8-619709e031d0_script\"></div>\n        <script>\n            (function () {\n                if (!window._renderLock) {\n                    window._renderLock = {}\n                }\n                if (window._renderLock[\"5aab9138-7de0-4dfe-a0b8-619709e031d0\"]) {\n                    return\n                }\n                window._renderLock[\"5aab9138-7de0-4dfe-a0b8-619709e031d0\"] = \"script\"\n                console.log(\"load as script\", Date.now())\n\n                window.render_container_id=\"container_id_5aab9138-7de0-4dfe-a0b8-619709e031d0_script\";\n                window.graph_json={\"pipeline\": {\"name\": \"image classification\", \"data_references\": {\"ImageNetSmallerTrainData\": {\"dataset_id\": \"ebe8ab07-56f9-4c3b-9474-5384e722b634\"}, \"ImageNetSmallerValidData\": {\"dataset_id\": \"7e69bcf0-bd9f-4262-a998-62673d6939b3\"}}, \"steps\": {\"838520ab\": {\"inputs\": {\"Input_dataset\": {\"source\": \"ImageNetSmallerTrainData\"}}, \"outputs\": {\"Output_image_directory\": {\"destination\": \"f67a749b-885a-495f-a6da-db2250467a74_Output_image_directory\"}}, \"module\": {\"id\": \"9a0e1b94-1914-58d1-9491-75d2444112c3\", \"version\": \"0.0.6.33\"}, \"validate\": {\"error\": [], \"module_id\": \"9a0e1b94-1914-58d1-9491-75d2444112c3\", \"namespace\": \"azureml\", \"module_name\": \"Convert to Image Directory\", \"module_version\": \"0.0.6.33\"}}, \"96580775\": {\"inputs\": {\"Input_dataset\": {\"source\": \"ImageNetSmallerValidData\"}}, \"outputs\": {\"Output_image_directory\": {\"destination\": \"1316f88c-05c7-4ceb-942b-8b10543ce352_Output_image_directory\"}}, \"module\": {\"id\": \"9a0e1b94-1914-58d1-9491-75d2444112c3\", \"version\": \"0.0.6.33\"}, \"validate\": {\"error\": [], \"module_id\": \"9a0e1b94-1914-58d1-9491-75d2444112c3\", \"namespace\": \"azureml\", \"module_name\": \"Convert to Image Directory\", \"module_version\": \"0.0.6.33\"}}, \"b0e306f7\": {\"inputs\": {}, \"outputs\": {\"Output_image_transformation\": {\"destination\": \"72b49d14-728c-4bca-891b-330329ea8f31_Output_image_transformation\"}}, \"module\": {\"id\": \"77621e71-437f-57cf-91fc-912af80e269d\", \"version\": \"0.0.6.33\"}, \"validate\": {\"error\": [], \"module_id\": \"77621e71-437f-57cf-91fc-912af80e269d\", \"namespace\": \"azureml\", \"module_name\": \"Init Image Transformation\", \"module_version\": \"0.0.6.33\"}}, \"82d08605\": {\"inputs\": {\"Input_image_transformation\": {\"source\": \"72b49d14-728c-4bca-891b-330329ea8f31_Output_image_transformation\"}, \"Input_image_directory\": {\"source\": \"f67a749b-885a-495f-a6da-db2250467a74_Output_image_directory\"}}, \"outputs\": {\"Output_image_directory\": {\"destination\": \"ba58d303-2f5b-45fc-b404-49d0302c5540_Output_image_directory\"}}, \"module\": {\"id\": \"aafa150a-4284-5016-8d20-d110b2c8f4d2\", \"version\": \"0.0.6.33\"}, \"validate\": {\"error\": [], \"module_id\": \"aafa150a-4284-5016-8d20-d110b2c8f4d2\", \"namespace\": \"azureml\", \"module_name\": \"Apply Image Transformation\", \"module_version\": \"0.0.6.33\"}}, \"49e0b774\": {\"inputs\": {\"Input_image_transformation\": {\"source\": \"72b49d14-728c-4bca-891b-330329ea8f31_Output_image_transformation\"}, \"Input_image_directory\": {\"source\": \"1316f88c-05c7-4ceb-942b-8b10543ce352_Output_image_directory\"}}, \"outputs\": {\"Output_image_directory\": {\"destination\": \"d175b0b9-0353-4c22-b670-dfff8627db17_Output_image_directory\"}}, \"module\": {\"id\": \"aafa150a-4284-5016-8d20-d110b2c8f4d2\", \"version\": \"0.0.6.33\"}, \"validate\": {\"error\": [], \"module_id\": \"aafa150a-4284-5016-8d20-d110b2c8f4d2\", \"namespace\": \"azureml\", \"module_name\": \"Apply Image Transformation\", \"module_version\": \"0.0.6.33\"}}, \"cf82fd2e\": {\"inputs\": {\"Train_Data\": {\"source\": \"ba58d303-2f5b-45fc-b404-49d0302c5540_Output_image_directory\"}, \"Valid_Data\": {\"source\": \"d175b0b9-0353-4c22-b670-dfff8627db17_Output_image_directory\"}}, \"outputs\": {\"Workspace\": {\"destination\": \"2a3d2d0c-9b42-46b5-919e-af311f4a7b65_Workspace\"}}, \"module\": {\"id\": \"9b9857e6-6e52-48d6-a68d-322726cb25fd\", \"version\": \"0.0.1\"}, \"validate\": {\"error\": [], \"module_id\": \"9b9857e6-6e52-48d6-a68d-322726cb25fd\", \"namespace\": \"itp-pilot\", \"module_name\": \"Train Image Classification\", \"module_version\": \"0.0.1\"}}}}, \"subGraphInfo\": [{\"name\": \"image classification\", \"description\": \"image classification\", \"defaultCompute\": \"k80-16-a\", \"id\": \"f4e29b1a-1dc4-4db9-a26e-e18c01582eb9\", \"parentGraphId\": null, \"inputs\": [{\"name\": \"ImageNetSmallerTrainData_f67a749b-885a-495f-a6da-db2250467a74\", \"external\": [], \"internal\": [{\"portName\": \"Input_dataset\", \"nodeId\": \"838520ab\"}]}, {\"name\": \"ImageNetSmallerValidData_1316f88c-05c7-4ceb-942b-8b10543ce352\", \"external\": [], \"internal\": [{\"portName\": \"Input_dataset\", \"nodeId\": \"96580775\"}]}], \"outputs\": []}], \"nodeIdToSubGraphIdMapping\": {\"838520ab\": \"f4e29b1a-1dc4-4db9-a26e-e18c01582eb9\", \"96580775\": \"f4e29b1a-1dc4-4db9-a26e-e18c01582eb9\", \"b0e306f7\": \"f4e29b1a-1dc4-4db9-a26e-e18c01582eb9\", \"82d08605\": \"f4e29b1a-1dc4-4db9-a26e-e18c01582eb9\", \"49e0b774\": \"f4e29b1a-1dc4-4db9-a26e-e18c01582eb9\", \"cf82fd2e\": \"f4e29b1a-1dc4-4db9-a26e-e18c01582eb9\"}, \"modules\": [{\"module_id\": \"9a0e1b94-1914-58d1-9491-75d2444112c3\", \"version\": \"0.0.6.33\", \"name\": \"Convert to Image Directory\", \"namespace\": \"azureml\", \"structured_interface\": {\"inputs\": [{\"name\": \"Input_dataset\", \"label\": \"Input dataset\", \"description\": \"Input dataset\"}], \"outputs\": [{\"name\": \"Output_image_directory\", \"label\": \"Output image directory\", \"description\": \"Output image directory.\"}]}}, {\"module_id\": \"77621e71-437f-57cf-91fc-912af80e269d\", \"version\": \"0.0.6.33\", \"name\": \"Init Image Transformation\", \"namespace\": \"azureml\", \"structured_interface\": {\"inputs\": [], \"outputs\": [{\"name\": \"Output_image_transformation\", \"label\": \"Output image transformation\", \"description\": \"Output image transformation\"}]}}, {\"module_id\": \"aafa150a-4284-5016-8d20-d110b2c8f4d2\", \"version\": \"0.0.6.33\", \"name\": \"Apply Image Transformation\", \"namespace\": \"azureml\", \"structured_interface\": {\"inputs\": [{\"name\": \"Input_image_transformation\", \"label\": \"Input image transformation\", \"description\": \"Input image transformation\"}, {\"name\": \"Input_image_directory\", \"label\": \"Input image directory\", \"description\": \"Input image directory\"}], \"outputs\": [{\"name\": \"Output_image_directory\", \"label\": \"Output image directory\", \"description\": \"Output image directory\"}]}}, {\"module_id\": \"9b9857e6-6e52-48d6-a68d-322726cb25fd\", \"version\": \"0.0.1\", \"name\": \"Train Image Classification\", \"namespace\": \"itp-pilot\", \"structured_interface\": {\"inputs\": [{\"name\": \"Train_Data\", \"label\": \"Train Data\", \"description\": \"path to train dataset\"}, {\"name\": \"Valid_Data\", \"label\": \"Valid Data\", \"description\": \"path to valid dataset\"}], \"outputs\": [{\"name\": \"Workspace\", \"label\": \"Workspace\", \"description\": \"path to directory where checkpoints will be stored\"}]}}], \"datasources\": [{\"name\": \"ImageNetSmallerTrainData\", \"description\": \"9100 images (7 categories * 1300 images per category)\", \"version\": 1, \"tags\": {}, \"registered_id\": \"ebe8ab07-56f9-4c3b-9474-5384e722b634\", \"saved_id\": \"2d9b2f23-0b1d-404c-8b47-d2216f3de763\", \"nodeId\": \"d3607c1e-36c4-35a0-a2d2-48f060868362\"}, {\"name\": \"ImageNetSmallerValidData\", \"description\": \"350 images (7 categories * 50 images per category)\", \"version\": 1, \"tags\": {}, \"registered_id\": \"7e69bcf0-bd9f-4262-a998-62673d6939b3\", \"saved_id\": \"38814658-e2b7-4900-a2d1-d65217185339\", \"nodeId\": \"ba788c1e-a219-3e6a-a738-4162aa272125\"}]};\n                window.env_json={\"subscription_id\": \"4aaa645c-5ae2-4ae9-a17a-84b9023bc56a\"};\n                window.before_script = performance.now();\n\n                var script = document.createElement('script')\n                script.src = \"https://yucongj.azureedge.net/libs/prod/0.0.4/index.js\"\n                document.getElementById(\"container_id_5aab9138-7de0-4dfe-a0b8-619709e031d0_script\").appendChild(script)\n            })()\n        </script>\n        "
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'result': 'validation passed', 'errors': []}"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "# validate pipeline and visualize the graph\n",
    "pipeline.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "k80-16-a not found in workspace, assume this is an AmlCompute\nSubmitted PipelineRun 77f02af4-6c5f-4179-9bb7-87348b741918\nLink to Azure Machine Learning Portal: https://ml.azure.com/experiments/image_classification/runs/77f02af4-6c5f-4179-9bb7-87348b741918?wsid=/subscriptions/4aaa645c-5ae2-4ae9-a17a-84b9023bc56a/resourcegroups/itp-pilot-ResGrp/workspaces/itp-pilot\nPipelineRunId: 77f02af4-6c5f-4179-9bb7-87348b741918\nLink to Azure Machine Learning Portal: https://ml.azure.com/experiments/image_classification/runs/77f02af4-6c5f-4179-9bb7-87348b741918?wsid=/subscriptions/4aaa645c-5ae2-4ae9-a17a-84b9023bc56a/resourcegroups/itp-pilot-ResGrp/workspaces/itp-pilot\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "try {\n    require.undef(\"validate_widget\")\n\n    define('validate_widget', [\"@jupyter-widgets/base\"], function(widgets) {\n        var ValidateView = widgets.DOMWidgetView.extend({\n            render () {\n                window.widget_self = this\n                var visualize_id = this.model.get('visualize_id')\n\n                if (!window._renderLock) {\n                    window._renderLock = {}\n                }\n                if (window._renderLock[visualize_id]) {\n                    return\n                }\n                window._renderLock[visualize_id] = \"widget\"\n                console.log(\"load as widget\", Date.now())\n\n                var lib_url = this.model.get('lib_url')\n                var graph_json = JSON.parse(this.model.get('graph_json'))\n                var env_json = JSON.parse(this.model.get('env_json'))\n                var container_id = this.model.get('container_id')\n\n                window.render_container_id = container_id\n                window.graph_json = graph_json\n                window.env_json = env_json\n                window.before_script = performance.now()\n\n                var container = document.createElement('div')\n                container.id = container_id\n                this.el.appendChild(container)\n\n                var style = document.createElement('style')\n                style.innerHTML = [\n                    \"#\", container_id, \" svg.react-dag-editor-svg-container { height: 800px; }\",\n                    \".cell-output-ipywidget-background { background: transparent !important }\"\n                ].join('')\n                this.el.appendChild(style)\n\n                this.model.on('msg:custom', dispatchMessage, this);\n\n                if (!window.__event_hub) {\n                    window.__event_hub = {}\n                }\n                if (!window.__event_hub[container_id]) {\n                    window.__event_hub[container_id] = {}\n                }\n\n                if (!window.__send_event) {\n                    window.__send_event = {}\n                }\n                window.__send_event[container_id] = sendMessage.bind(this)\n\n                function sendMessage(message, uid, content) {\n                    return new Promise((resolve) => {\n                        this.model.send({\n                            message: `${message}:request`,\n                            body: {\n                                uid,\n                                content\n                            }\n                        })\n    \n                        var respMessageKey = `${message}:response`\n                        if (!window.__event_hub[container_id][respMessageKey]) {\n                            window.__event_hub[container_id][respMessageKey] = []\n                        }\n                        window.__event_hub[container_id][respMessageKey].push(callback)\n    \n                        function callback (response) {\n                            if (response.uid !== uid) {\n                                return\n                            }\n\n                            var idx = window.__event_hub[container_id][respMessageKey].indexOf(callback) \n                            window.__event_hub[container_id][respMessageKey].splice(idx, 1)\n                            \n                            resolve(response)\n                        }\n                    })\n                }\n\n                function dispatchMessage (rawMessage) {\n                    var message = rawMessage.message\n                    var body = rawMessage.body\n\n                    if (!window.__event_hub[container_id][message]) {\n                        window.__event_hub[container_id][message] = []\n                    }\n                    var listeners = window.__event_hub[container_id][message]\n\n                    listeners.forEach(cb => {\n                        try {\n                            cb(body)\n                        } catch (e) {\n                            console.error(\"Unexpected error in listener\", e)\n                        }\n                    })\n\n                    console.log(body)\n                }\n\n                var script = document.createElement('script')\n                script.src = lib_url\n                this.el.appendChild(script)\n            }\n        });\n\n        return {\n            ValidateView\n        }\n    })\n} catch (e) {\n    console.log(\"create validation widget failed\", e)\n}"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "ValidateView(container_id='container_id_5acebb1f-a799-435f-b290-d4967d88c8ef_widget', env_json='{}', graph_jso…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8389b87aa9424834936fe8703cadd3d2"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n        <style>\n        #container_id_5acebb1f-a799-435f-b290-d4967d88c8ef_script svg.react-dag-editor-svg-container {\n            height: 800px;\n        }\n        </style>\n        <div id=\"container_id_5acebb1f-a799-435f-b290-d4967d88c8ef_script\"></div>\n        <script>\n            (function () {\n                if (!window._renderLock) {\n                    window._renderLock = {}\n                }\n                if (window._renderLock[\"5acebb1f-a799-435f-b290-d4967d88c8ef\"]) {\n                    return\n                }\n                window._renderLock[\"5acebb1f-a799-435f-b290-d4967d88c8ef\"] = \"script\"\n                console.log(\"load as script\", Date.now())\n\n                window.render_container_id=\"container_id_5acebb1f-a799-435f-b290-d4967d88c8ef_script\";\n                window.graph_json={\"pipeline\": {\"name\": \"image classification\", \"data_references\": {\"ImageNetSmallerTrainData\": {\"dataset_id\": \"ebe8ab07-56f9-4c3b-9474-5384e722b634\"}, \"ImageNetSmallerValidData\": {\"dataset_id\": \"7e69bcf0-bd9f-4262-a998-62673d6939b3\"}}, \"steps\": {\"40c505eb\": {\"inputs\": {\"Input_dataset\": {\"source\": \"ImageNetSmallerTrainData\"}}, \"outputs\": {\"Output_image_directory\": {\"destination\": \"f67a749b-885a-495f-a6da-db2250467a74_Output_image_directory\"}}, \"module\": {\"id\": \"9a0e1b94-1914-58d1-9491-75d2444112c3\", \"version\": \"0.0.6.33\"}, \"validate\": {\"error\": [], \"module_id\": \"9a0e1b94-1914-58d1-9491-75d2444112c3\", \"namespace\": \"azureml\", \"module_name\": \"Convert to Image Directory\", \"module_version\": \"0.0.6.33\"}}, \"d6804476\": {\"inputs\": {\"Input_dataset\": {\"source\": \"ImageNetSmallerValidData\"}}, \"outputs\": {\"Output_image_directory\": {\"destination\": \"1316f88c-05c7-4ceb-942b-8b10543ce352_Output_image_directory\"}}, \"module\": {\"id\": \"9a0e1b94-1914-58d1-9491-75d2444112c3\", \"version\": \"0.0.6.33\"}, \"validate\": {\"error\": [], \"module_id\": \"9a0e1b94-1914-58d1-9491-75d2444112c3\", \"namespace\": \"azureml\", \"module_name\": \"Convert to Image Directory\", \"module_version\": \"0.0.6.33\"}}, \"2edaf8bc\": {\"inputs\": {}, \"outputs\": {\"Output_image_transformation\": {\"destination\": \"72b49d14-728c-4bca-891b-330329ea8f31_Output_image_transformation\"}}, \"module\": {\"id\": \"77621e71-437f-57cf-91fc-912af80e269d\", \"version\": \"0.0.6.33\"}, \"validate\": {\"error\": [], \"module_id\": \"77621e71-437f-57cf-91fc-912af80e269d\", \"namespace\": \"azureml\", \"module_name\": \"Init Image Transformation\", \"module_version\": \"0.0.6.33\"}}, \"912e9384\": {\"inputs\": {\"Input_image_transformation\": {\"source\": \"72b49d14-728c-4bca-891b-330329ea8f31_Output_image_transformation\"}, \"Input_image_directory\": {\"source\": \"f67a749b-885a-495f-a6da-db2250467a74_Output_image_directory\"}}, \"outputs\": {\"Output_image_directory\": {\"destination\": \"ba58d303-2f5b-45fc-b404-49d0302c5540_Output_image_directory\"}}, \"module\": {\"id\": \"aafa150a-4284-5016-8d20-d110b2c8f4d2\", \"version\": \"0.0.6.33\"}, \"validate\": {\"error\": [], \"module_id\": \"aafa150a-4284-5016-8d20-d110b2c8f4d2\", \"namespace\": \"azureml\", \"module_name\": \"Apply Image Transformation\", \"module_version\": \"0.0.6.33\"}}, \"2e2fda48\": {\"inputs\": {\"Input_image_transformation\": {\"source\": \"72b49d14-728c-4bca-891b-330329ea8f31_Output_image_transformation\"}, \"Input_image_directory\": {\"source\": \"1316f88c-05c7-4ceb-942b-8b10543ce352_Output_image_directory\"}}, \"outputs\": {\"Output_image_directory\": {\"destination\": \"d175b0b9-0353-4c22-b670-dfff8627db17_Output_image_directory\"}}, \"module\": {\"id\": \"aafa150a-4284-5016-8d20-d110b2c8f4d2\", \"version\": \"0.0.6.33\"}, \"validate\": {\"error\": [], \"module_id\": \"aafa150a-4284-5016-8d20-d110b2c8f4d2\", \"namespace\": \"azureml\", \"module_name\": \"Apply Image Transformation\", \"module_version\": \"0.0.6.33\"}}, \"7795ac52\": {\"inputs\": {\"Train_Data\": {\"source\": \"ba58d303-2f5b-45fc-b404-49d0302c5540_Output_image_directory\"}, \"Valid_Data\": {\"source\": \"d175b0b9-0353-4c22-b670-dfff8627db17_Output_image_directory\"}}, \"outputs\": {\"Workspace\": {\"destination\": \"2a3d2d0c-9b42-46b5-919e-af311f4a7b65_Workspace\"}}, \"module\": {\"id\": \"9b9857e6-6e52-48d6-a68d-322726cb25fd\", \"version\": \"0.0.1\"}, \"validate\": {\"error\": [], \"module_id\": \"9b9857e6-6e52-48d6-a68d-322726cb25fd\", \"namespace\": \"itp-pilot\", \"module_name\": \"Train Image Classification\", \"module_version\": \"0.0.1\"}}}}, \"subGraphInfo\": [{\"name\": \"image classification\", \"description\": \"image classification\", \"defaultCompute\": \"k80-16-a\", \"id\": \"f4e29b1a-1dc4-4db9-a26e-e18c01582eb9\", \"parentGraphId\": null, \"inputs\": [{\"name\": \"ImageNetSmallerTrainData_f67a749b-885a-495f-a6da-db2250467a74\", \"external\": [], \"internal\": [{\"portName\": \"Input_dataset\", \"nodeId\": \"40c505eb\"}]}, {\"name\": \"ImageNetSmallerValidData_1316f88c-05c7-4ceb-942b-8b10543ce352\", \"external\": [], \"internal\": [{\"portName\": \"Input_dataset\", \"nodeId\": \"d6804476\"}]}], \"outputs\": []}], \"nodeIdToSubGraphIdMapping\": {\"40c505eb\": \"f4e29b1a-1dc4-4db9-a26e-e18c01582eb9\", \"d6804476\": \"f4e29b1a-1dc4-4db9-a26e-e18c01582eb9\", \"2edaf8bc\": \"f4e29b1a-1dc4-4db9-a26e-e18c01582eb9\", \"912e9384\": \"f4e29b1a-1dc4-4db9-a26e-e18c01582eb9\", \"2e2fda48\": \"f4e29b1a-1dc4-4db9-a26e-e18c01582eb9\", \"7795ac52\": \"f4e29b1a-1dc4-4db9-a26e-e18c01582eb9\"}, \"modules\": [{\"module_id\": \"9a0e1b94-1914-58d1-9491-75d2444112c3\", \"version\": \"0.0.6.33\", \"name\": \"Convert to Image Directory\", \"namespace\": \"azureml\", \"structured_interface\": {\"inputs\": [{\"name\": \"Input_dataset\", \"label\": \"Input dataset\", \"description\": \"Input dataset\"}], \"outputs\": [{\"name\": \"Output_image_directory\", \"label\": \"Output image directory\", \"description\": \"Output image directory.\"}]}}, {\"module_id\": \"77621e71-437f-57cf-91fc-912af80e269d\", \"version\": \"0.0.6.33\", \"name\": \"Init Image Transformation\", \"namespace\": \"azureml\", \"structured_interface\": {\"inputs\": [], \"outputs\": [{\"name\": \"Output_image_transformation\", \"label\": \"Output image transformation\", \"description\": \"Output image transformation\"}]}}, {\"module_id\": \"aafa150a-4284-5016-8d20-d110b2c8f4d2\", \"version\": \"0.0.6.33\", \"name\": \"Apply Image Transformation\", \"namespace\": \"azureml\", \"structured_interface\": {\"inputs\": [{\"name\": \"Input_image_transformation\", \"label\": \"Input image transformation\", \"description\": \"Input image transformation\"}, {\"name\": \"Input_image_directory\", \"label\": \"Input image directory\", \"description\": \"Input image directory\"}], \"outputs\": [{\"name\": \"Output_image_directory\", \"label\": \"Output image directory\", \"description\": \"Output image directory\"}]}}, {\"module_id\": \"9b9857e6-6e52-48d6-a68d-322726cb25fd\", \"version\": \"0.0.1\", \"name\": \"Train Image Classification\", \"namespace\": \"itp-pilot\", \"structured_interface\": {\"inputs\": [{\"name\": \"Train_Data\", \"label\": \"Train Data\", \"description\": \"path to train dataset\"}, {\"name\": \"Valid_Data\", \"label\": \"Valid Data\", \"description\": \"path to valid dataset\"}], \"outputs\": [{\"name\": \"Workspace\", \"label\": \"Workspace\", \"description\": \"path to directory where checkpoints will be stored\"}]}}], \"datasources\": [{\"name\": \"ImageNetSmallerTrainData\", \"description\": \"9100 images (7 categories * 1300 images per category)\", \"version\": 1, \"tags\": {}, \"registered_id\": \"ebe8ab07-56f9-4c3b-9474-5384e722b634\", \"saved_id\": \"2d9b2f23-0b1d-404c-8b47-d2216f3de763\", \"nodeId\": \"d3607c1e-36c4-35a0-a2d2-48f060868362\"}, {\"name\": \"ImageNetSmallerValidData\", \"description\": \"350 images (7 categories * 50 images per category)\", \"version\": 1, \"tags\": {}, \"registered_id\": \"7e69bcf0-bd9f-4262-a998-62673d6939b3\", \"saved_id\": \"38814658-e2b7-4900-a2d1-d65217185339\", \"nodeId\": \"ba788c1e-a219-3e6a-a738-4162aa272125\"}]};\n                window.env_json={};\n                window.before_script = performance.now();\n\n                var script = document.createElement('script')\n                script.src = \"https://yucongj.azureedge.net/libs/prod/0.0.4/index.js\"\n                document.getElementById(\"container_id_5acebb1f-a799-435f-b290-d4967d88c8ef_script\").appendChild(script)\n            })()\n        </script>\n        "
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<RunStatus.failed: 'Failed'>"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "# submit a pipeline run\n",
    "pipeline.submit(experiment_name='image_classification').wait_for_completion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}