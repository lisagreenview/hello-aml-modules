{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Classification Training Pipeline\n",
    "\n",
    "In this sample, image preprocessing is on cpu nodes while training on distributed gpu nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from azureml.core import Workspace\n",
    "from azureml.core.compute import AmlCompute, ComputeTarget\n",
    "from azureml.pipeline.wrapper import Module, Pipeline, dsl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure workspace and compute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "WARNING - Warning: Falling back to use azure cli login credentials.\nIf you run your code in unattended mode, i.e., where you can't give a user input, then we recommend to use ServicePrincipalAuthentication or MsiAuthentication.\nPlease refer to aka.ms/aml-notebook-auth for different authentication mechanisms in azureml-sdk.\nitp-pilot\nitp-pilot-ResGrp\nwesteurope\n4aaa645c-5ae2-4ae9-a17a-84b9023bc56a\n"
    }
   ],
   "source": [
    "# configure workspace information here.\n",
    "workspace = Workspace.get(\n",
    "    name='itp-pilot',\n",
    "    subscription_id='4aaa645c-5ae2-4ae9-a17a-84b9023bc56a',\n",
    "    resource_group='itp-pilot-ResGrp'\n",
    ")\n",
    "print(workspace.name, workspace.resource_group, workspace.location, workspace.subscription_id, sep = '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Found existing gpu compute target: gpu-cluster\nFound existing cpu compute target: compute-ds3v2\n"
    }
   ],
   "source": [
    "# specify aml compute name.\n",
    "gpu_compute_target = 'gpu-cluster'\n",
    "cpu_compute_target = 'compute-ds3v2'\n",
    "try:\n",
    "    gpu_compute = AmlCompute(workspace, gpu_compute_target)\n",
    "    print(\"Found existing gpu compute target: {}\".format(gpu_compute_target))\n",
    "except:\n",
    "    print(\"Need to create a new gpu compute\")\n",
    "    provisioning_config = AmlCompute.provisioning_configuration(vm_size = \"STANDARD_NC6\",\n",
    "                                                                min_nodes = 0, \n",
    "                                                                max_nodes = 4)\n",
    "    gpu_compute = ComputeTarget.create(workspace, gpu_compute_target, provisioning_config)\n",
    "    gpu_compute.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=20)\n",
    "\n",
    "try:\n",
    "    cpu_compute = AmlCompute(workspace, cpu_compute_target)\n",
    "    print(\"Found existing cpu compute target: {}\".format(cpu_compute_target))\n",
    "except:\n",
    "    print(\"Creating a new cpu compute target: {}\".format(cpu_compute_target))  \n",
    "    provisioning_config = AmlCompute.provisioning_configuration(vm_size = \"STANDARD_DS3_V2\",\n",
    "                                                                min_nodes = 0, \n",
    "                                                                max_nodes = 4)    \n",
    "    cpu_compute = ComputeTarget.create(workspace, cpu_compute_target, provisioning_config)\n",
    "    cpu_compute.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare dataset\n",
    "This smaller imagenet dataset is a subset of the official one.\n",
    "- training dataset contains 9100 images (7 categories * 1300 images per category)\n",
    "- validation dataset contains 350 images (7 categories * 50 images per category)\n",
    "\n",
    "Need to use zip file here to avoid perf issue of mounting file dataset with many subfolders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dataset\n",
    "from azureml.core.dataset import Dataset\n",
    "\n",
    "train_image_dataset = Dataset.get_by_name(workspace, name='ImageNetSmallerTrainData')\n",
    "val_image_dataset = Dataset.get_by_name(workspace, name='ImageNetSmallerValidData')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load built-in modules\n",
    "convert_func = Module.load(workspace, namespace='azureml', name='Convert to Image Directory')\n",
    "init_transform_func = Module.load(workspace, namespace='azureml', name='Init Image Transformation')\n",
    "apply_transform_func = Module.load(workspace, namespace='azureml', name='Apply Image Transformation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load local modules\n",
    "# this train module is a mpi module.\n",
    "module_folder = r'./modules'\n",
    "yaml_file_name = 'entry.spec.yaml'\n",
    "train_module = Module.from_yaml(workspace, yaml_file=f'{module_folder}/ConvNets/{yaml_file_name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up a pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define pipeline\n",
    "@dsl.pipeline(name='image classification', description='image classification', default_compute_target='compute-ds3v2')\n",
    "def generated_pipeline():\n",
    "    convert_train = convert_func(\n",
    "        input_dataset=train_image_dataset\n",
    "    )\n",
    "    \n",
    "    convert_val = convert_func(\n",
    "        input_dataset=val_image_dataset\n",
    "    )\n",
    "    \n",
    "    init_trans = init_transform_func(\n",
    "        resize='False',\n",
    "        size=256,\n",
    "        center_crop='False',\n",
    "        crop_size=224,\n",
    "        pad='False',\n",
    "        padding=0,\n",
    "        color_jitter='False',\n",
    "        grayscale='False',\n",
    "        random_resized_crop='False',\n",
    "        random_resized_crop_size=256,\n",
    "        random_crop='False',\n",
    "        random_crop_size=224,\n",
    "        random_horizontal_flip='True',\n",
    "        random_vertical_flip='False',\n",
    "        random_rotation='False',\n",
    "        random_rotation_degrees=0,\n",
    "        random_affine='False',\n",
    "        random_affine_degrees=0,\n",
    "        random_grayscale='False',\n",
    "        random_perspective='False'\n",
    "    )\n",
    "    \n",
    "    apply_trans_on_train = apply_transform_func(\n",
    "        mode='For training',\n",
    "        input_image_transformation=init_trans.outputs.output_image_transformation,\n",
    "        input_image_directory=convert_train.outputs.output_image_directory\n",
    "    )\n",
    "    \n",
    "    apply_trans_on_val = apply_transform_func(\n",
    "        mode='For inference',\n",
    "        input_image_transformation=init_trans.outputs.output_image_transformation,\n",
    "        input_image_directory=convert_val.outputs.output_image_directory\n",
    "    )\n",
    "    \n",
    "    train = train_module(\n",
    "        train_data=apply_trans_on_train.outputs.output_image_directory,\n",
    "        valid_data=apply_trans_on_val.outputs.output_image_directory,\n",
    "        data_backend='pytorch',\n",
    "        pretrained_weights=None,\n",
    "        epochs=4,\n",
    "        seed=123,\n",
    "        batch_size=16,\n",
    "        save_checkpoint_epochs=2\n",
    "    )\n",
    "    # perform distributed training with 2 nodes.\n",
    "    # note: process_count_per_node should be 1 because this module will launch distributed processes based on node device count.\n",
    "    train.runsettings.configure(target=gpu_compute_target, node_count=2, process_count_per_node=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a pipeline\n",
    "pipeline = generated_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "try {\n    require.undef(\"validate_widget\")\n\n    define('validate_widget', [\"@jupyter-widgets/base\"], function(widgets) {\n        var ValidateView = widgets.DOMWidgetView.extend({\n            render () {\n                window.widget_self = this\n                var visualize_id = this.model.get('visualize_id')\n\n                if (!window._renderLock) {\n                    window._renderLock = {}\n                }\n                if (window._renderLock[visualize_id]) {\n                    return\n                }\n                window._renderLock[visualize_id] = \"widget\"\n                console.log(\"load as widget\", Date.now())\n\n                var lib_url = this.model.get('lib_url')\n                var graph_json = JSON.parse(this.model.get('graph_json'))\n                var env_json = JSON.parse(this.model.get('env_json'))\n                var container_id = this.model.get('container_id')\n\n                window.render_container_id = container_id\n                window.graph_json = graph_json\n                window.env_json = env_json\n                window.before_script = performance.now()\n\n                var container = document.createElement('div')\n                container.id = container_id\n                this.el.appendChild(container)\n\n                var style = document.createElement('style')\n                style.innerHTML = [\n                    \"#\", container_id, \" svg.react-dag-editor-svg-container { height: 800px; }\",\n                    \".cell-output-ipywidget-background { background: transparent !important }\"\n                ].join('')\n                this.el.appendChild(style)\n\n                this.model.on('msg:custom', dispatchMessage, this);\n\n                if (!window.__event_hub) {\n                    window.__event_hub = {}\n                }\n                if (!window.__event_hub[container_id]) {\n                    window.__event_hub[container_id] = {}\n                }\n\n                if (!window.__send_event) {\n                    window.__send_event = {}\n                }\n                window.__send_event[container_id] = sendMessage.bind(this)\n\n                function sendMessage(message, uid, content) {\n                    return new Promise((resolve) => {\n                        this.model.send({\n                            message: `${message}:request`,\n                            body: {\n                                uid,\n                                content\n                            }\n                        })\n    \n                        var respMessageKey = `${message}:response`\n                        if (!window.__event_hub[container_id][respMessageKey]) {\n                            window.__event_hub[container_id][respMessageKey] = []\n                        }\n                        window.__event_hub[container_id][respMessageKey].push(callback)\n    \n                        function callback (response) {\n                            if (response.uid !== uid) {\n                                return\n                            }\n\n                            var idx = window.__event_hub[container_id][respMessageKey].indexOf(callback) \n                            window.__event_hub[container_id][respMessageKey].splice(idx, 1)\n                            \n                            resolve(response)\n                        }\n                    })\n                }\n\n                function dispatchMessage (rawMessage) {\n                    var message = rawMessage.message\n                    var body = rawMessage.body\n\n                    if (!window.__event_hub[container_id][message]) {\n                        window.__event_hub[container_id][message] = []\n                    }\n                    var listeners = window.__event_hub[container_id][message]\n\n                    listeners.forEach(cb => {\n                        try {\n                            cb(body)\n                        } catch (e) {\n                            console.error(\"Unexpected error in listener\", e)\n                        }\n                    })\n\n                    console.log(body)\n                }\n\n                var script = document.createElement('script')\n                script.src = lib_url\n                this.el.appendChild(script)\n            }\n        });\n\n        return {\n            ValidateView\n        }\n    })\n} catch (e) {\n    console.log(\"create validation widget failed\", e)\n}"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "ValidateView(container_id='container_id_20d51ad4-9ab7-44aa-b4e6-90ec2da7b9c7_widget', env_json='{\"subscriptionâ€¦",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8b0ea76f31aa47fd8723cb0ed979a18b"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n        <style>\n        #container_id_20d51ad4-9ab7-44aa-b4e6-90ec2da7b9c7_script svg.react-dag-editor-svg-container {\n            height: 800px;\n        }\n        </style>\n        <div id=\"container_id_20d51ad4-9ab7-44aa-b4e6-90ec2da7b9c7_script\"></div>\n        <script>\n            (function () {\n                if (!window._renderLock) {\n                    window._renderLock = {}\n                }\n                if (window._renderLock[\"20d51ad4-9ab7-44aa-b4e6-90ec2da7b9c7\"]) {\n                    return\n                }\n                window._renderLock[\"20d51ad4-9ab7-44aa-b4e6-90ec2da7b9c7\"] = \"script\"\n                console.log(\"load as script\", Date.now())\n\n                window.render_container_id=\"container_id_20d51ad4-9ab7-44aa-b4e6-90ec2da7b9c7_script\";\n                window.graph_json={\"pipeline\": {\"name\": \"image classification\", \"data_references\": {\"ImageNetSmallerTrainData\": {\"dataset_id\": \"ebe8ab07-56f9-4c3b-9474-5384e722b634\"}, \"ImageNetSmallerValidData\": {\"dataset_id\": \"7e69bcf0-bd9f-4262-a998-62673d6939b3\"}}, \"steps\": {\"8172c501\": {\"inputs\": {\"Input_dataset\": {\"source\": \"ImageNetSmallerTrainData\"}}, \"outputs\": {\"Output_image_directory\": {\"destination\": \"12a0f88e-07cc-45fc-8bb1-5d52da6c080d_Output_image_directory\"}}, \"module\": {\"id\": \"9a0e1b94-1914-58d1-9491-75d2444112c3\", \"version\": \"0.0.6.33\"}, \"validate\": {\"error\": [], \"module_id\": \"9a0e1b94-1914-58d1-9491-75d2444112c3\", \"namespace\": \"azureml\", \"module_name\": \"Convert to Image Directory\", \"module_version\": \"0.0.6.33\"}}, \"3afb5b5c\": {\"inputs\": {\"Input_dataset\": {\"source\": \"ImageNetSmallerValidData\"}}, \"outputs\": {\"Output_image_directory\": {\"destination\": \"db638eb7-5c1f-4eca-a11a-8f9c554695b1_Output_image_directory\"}}, \"module\": {\"id\": \"9a0e1b94-1914-58d1-9491-75d2444112c3\", \"version\": \"0.0.6.33\"}, \"validate\": {\"error\": [], \"module_id\": \"9a0e1b94-1914-58d1-9491-75d2444112c3\", \"namespace\": \"azureml\", \"module_name\": \"Convert to Image Directory\", \"module_version\": \"0.0.6.33\"}}, \"40d59299\": {\"inputs\": {}, \"outputs\": {\"Output_image_transformation\": {\"destination\": \"6a02f6fc-1cfa-4b6f-98a0-bdbf76638105_Output_image_transformation\"}}, \"module\": {\"id\": \"77621e71-437f-57cf-91fc-912af80e269d\", \"version\": \"0.0.6.33\"}, \"validate\": {\"error\": [], \"module_id\": \"77621e71-437f-57cf-91fc-912af80e269d\", \"namespace\": \"azureml\", \"module_name\": \"Init Image Transformation\", \"module_version\": \"0.0.6.33\"}}, \"acdc7433\": {\"inputs\": {\"Input_image_transformation\": {\"source\": \"6a02f6fc-1cfa-4b6f-98a0-bdbf76638105_Output_image_transformation\"}, \"Input_image_directory\": {\"source\": \"12a0f88e-07cc-45fc-8bb1-5d52da6c080d_Output_image_directory\"}}, \"outputs\": {\"Output_image_directory\": {\"destination\": \"183967de-b049-403b-8164-43f1543c4187_Output_image_directory\"}}, \"module\": {\"id\": \"aafa150a-4284-5016-8d20-d110b2c8f4d2\", \"version\": \"0.0.6.33\"}, \"validate\": {\"error\": [], \"module_id\": \"aafa150a-4284-5016-8d20-d110b2c8f4d2\", \"namespace\": \"azureml\", \"module_name\": \"Apply Image Transformation\", \"module_version\": \"0.0.6.33\"}}, \"4e7d2187\": {\"inputs\": {\"Input_image_transformation\": {\"source\": \"6a02f6fc-1cfa-4b6f-98a0-bdbf76638105_Output_image_transformation\"}, \"Input_image_directory\": {\"source\": \"db638eb7-5c1f-4eca-a11a-8f9c554695b1_Output_image_directory\"}}, \"outputs\": {\"Output_image_directory\": {\"destination\": \"60fd11f0-0a05-4fdc-a43d-aeaf5cb71b5b_Output_image_directory\"}}, \"module\": {\"id\": \"aafa150a-4284-5016-8d20-d110b2c8f4d2\", \"version\": \"0.0.6.33\"}, \"validate\": {\"error\": [], \"module_id\": \"aafa150a-4284-5016-8d20-d110b2c8f4d2\", \"namespace\": \"azureml\", \"module_name\": \"Apply Image Transformation\", \"module_version\": \"0.0.6.33\"}}, \"19a5ccdb\": {\"inputs\": {\"Train_Data\": {\"source\": \"183967de-b049-403b-8164-43f1543c4187_Output_image_directory\"}, \"Valid_Data\": {\"source\": \"60fd11f0-0a05-4fdc-a43d-aeaf5cb71b5b_Output_image_directory\"}}, \"outputs\": {\"Workspace\": {\"destination\": \"020051a7-210f-43d5-800d-0ca516042e0c_Workspace\"}}, \"module\": {\"id\": \"a6a8e433-d23b-4bed-89f3-79d0545bf183\", \"version\": \"0.0.1\"}, \"validate\": {\"error\": [], \"module_id\": \"a6a8e433-d23b-4bed-89f3-79d0545bf183\", \"namespace\": \"itp-pilot\", \"module_name\": \"Train Image Classification\", \"module_version\": \"0.0.1\"}}}}, \"subGraphInfo\": [{\"name\": \"image classification\", \"description\": \"image classification\", \"defaultCompute\": \"compute-ds3v2\", \"id\": \"b004a241-5469-4dd0-955c-436afdbe8f36\", \"parentGraphId\": null, \"inputs\": [{\"name\": \"ImageNetSmallerTrainData_12a0f88e-07cc-45fc-8bb1-5d52da6c080d\", \"external\": [], \"internal\": [{\"portName\": \"Input_dataset\", \"nodeId\": \"8172c501\"}]}, {\"name\": \"ImageNetSmallerValidData_db638eb7-5c1f-4eca-a11a-8f9c554695b1\", \"external\": [], \"internal\": [{\"portName\": \"Input_dataset\", \"nodeId\": \"3afb5b5c\"}]}], \"outputs\": []}], \"nodeIdToSubGraphIdMapping\": {\"8172c501\": \"b004a241-5469-4dd0-955c-436afdbe8f36\", \"3afb5b5c\": \"b004a241-5469-4dd0-955c-436afdbe8f36\", \"40d59299\": \"b004a241-5469-4dd0-955c-436afdbe8f36\", \"acdc7433\": \"b004a241-5469-4dd0-955c-436afdbe8f36\", \"4e7d2187\": \"b004a241-5469-4dd0-955c-436afdbe8f36\", \"19a5ccdb\": \"b004a241-5469-4dd0-955c-436afdbe8f36\"}, \"modules\": [{\"module_id\": \"9a0e1b94-1914-58d1-9491-75d2444112c3\", \"version\": \"0.0.6.33\", \"name\": \"Convert to Image Directory\", \"namespace\": \"azureml\", \"structured_interface\": {\"inputs\": [{\"name\": \"Input_dataset\", \"label\": \"Input dataset\", \"description\": \"Input dataset\"}], \"outputs\": [{\"name\": \"Output_image_directory\", \"label\": \"Output image directory\", \"description\": \"Output image directory.\"}]}}, {\"module_id\": \"77621e71-437f-57cf-91fc-912af80e269d\", \"version\": \"0.0.6.33\", \"name\": \"Init Image Transformation\", \"namespace\": \"azureml\", \"structured_interface\": {\"inputs\": [], \"outputs\": [{\"name\": \"Output_image_transformation\", \"label\": \"Output image transformation\", \"description\": \"Output image transformation\"}]}}, {\"module_id\": \"aafa150a-4284-5016-8d20-d110b2c8f4d2\", \"version\": \"0.0.6.33\", \"name\": \"Apply Image Transformation\", \"namespace\": \"azureml\", \"structured_interface\": {\"inputs\": [{\"name\": \"Input_image_transformation\", \"label\": \"Input image transformation\", \"description\": \"Input image transformation\"}, {\"name\": \"Input_image_directory\", \"label\": \"Input image directory\", \"description\": \"Input image directory\"}], \"outputs\": [{\"name\": \"Output_image_directory\", \"label\": \"Output image directory\", \"description\": \"Output image directory\"}]}}, {\"module_id\": \"a6a8e433-d23b-4bed-89f3-79d0545bf183\", \"version\": \"0.0.1\", \"name\": \"Train Image Classification\", \"namespace\": \"itp-pilot\", \"structured_interface\": {\"inputs\": [{\"name\": \"Train_Data\", \"label\": \"Train Data\", \"description\": \"path to train dataset\"}, {\"name\": \"Valid_Data\", \"label\": \"Valid Data\", \"description\": \"path to valid dataset\"}], \"outputs\": [{\"name\": \"Workspace\", \"label\": \"Workspace\", \"description\": \"path to directory where checkpoints will be stored\"}]}}], \"datasources\": [{\"name\": \"ImageNetSmallerTrainData\", \"description\": \"9100 images (7 categories * 1300 images per category)\", \"version\": 1, \"tags\": {}, \"registered_id\": \"ebe8ab07-56f9-4c3b-9474-5384e722b634\", \"saved_id\": \"2d9b2f23-0b1d-404c-8b47-d2216f3de763\", \"nodeId\": \"d3607c1e-36c4-35a0-a2d2-48f060868362\"}, {\"name\": \"ImageNetSmallerValidData\", \"description\": \"350 images (7 categories * 50 images per category)\", \"version\": 1, \"tags\": {}, \"registered_id\": \"7e69bcf0-bd9f-4262-a998-62673d6939b3\", \"saved_id\": \"38814658-e2b7-4900-a2d1-d65217185339\", \"nodeId\": \"ba788c1e-a219-3e6a-a738-4162aa272125\"}]};\n                window.env_json={\"subscription_id\": \"4aaa645c-5ae2-4ae9-a17a-84b9023bc56a\"};\n                window.before_script = performance.now();\n\n                var script = document.createElement('script')\n                script.src = \"https://yucongj.azureedge.net/libs/prod/0.0.4/index.js\"\n                document.getElementById(\"container_id_20d51ad4-9ab7-44aa-b4e6-90ec2da7b9c7_script\").appendChild(script)\n            })()\n        </script>\n        "
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'result': 'validation passed', 'errors': []}"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "# validate pipeline and visualize the graph\n",
    "pipeline.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submit a pipeline run\n",
    "pipeline.submit(experiment_name='image_classification').wait_for_completion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}