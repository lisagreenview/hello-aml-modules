{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build AML Pipeline with azureml modules\n",
    "\n",
    "In this tutorial you will learn how to work with Azure ML module:\n",
    "\n",
    "1. Setup enrivonment - install module CLI and module/pipeline SDK\n",
    "2. Register a few sample modules into your aml workspace using CLI\n",
    "3. Use module/pipeline SDK to create a pipeline with modules registered in step 2\n",
    "\n",
    "## Prerequisite\n",
    "* Install Azure CLI, please follow [the Azure CLI installation instructions](https://docs.microsoft.com/en-us/cli/azure/install-azure-cli?view=azure-cli-latest) to install.\n",
    "* Install docker desktop from [here](https://www.docker.com/products/docker-desktop) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup environment\n",
    "* Install Azure CLI AML extension which includes the _module_ command group\n",
    "* Install Azure ML SDK including the APIs to work with _module_ and _pipeline_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLI_SDK_VERSION=31132438"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!az extension remove -n azure-cli-ml \n",
    "\n",
    "# Install local version of azure-cli-ml (which includes `az ml module` commands)\n",
    "!az extension add --source https://azuremlsdktestpypi.azureedge.net/CLI-SDK-Runners-Validation/$CLI_SDK_VERSION/azure_cli_ml-0.1.0.$CLI_SDK_VERSION-py3-none-any.whl --pip-extra-index-urls https://azuremlsdktestpypi.azureedge.net/CLI-SDK-Runners-Validation/$CLI_SDK_VERSION --yes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify the availability of `az ml module` commands\n",
    "#!az ml pipeline -h\n",
    "!az ml module -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Install azureml-sdk with Pipeline, Module\r\n",
    "# Important! After install succeed, need to restart kernel\r\n",
    "\r\n",
    "#%config IPCompleter.greedy=True \r\n",
    "#!pip install azureml-pipeline-wrapper[notebooks]==0.1.0.$CLI_SDK_VERSION --extra-index-url https://azuremlsdktestpypi.azureedge.net/CLI-SDK-Runners-Validation/$CLI_SDK_VERSION --user --upgrade \r\n",
    "#!pip install azureml-core==0.1.0.$CLI_SDK_VERSION --extra-index-url https://azuremlsdktestpypi.azureedge.net/CLI-SDK-Runners-Validation/$CLI_SDK_VERSION --user --upgrade \r\n",
    "\r\n",
    "!pip install azure-ml-component[notebooks] --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Register azureml module\n",
    "\n",
    "You can manage AML module through [azure-cli-ml](https://aka.ms/moduledoc) or [ml.azure.com](https://ml.azure.com/). <br>\n",
    "\n",
    "Module could be registered from:\n",
    "- local path\n",
    "- public Github url\n",
    "- Azure DevOps build artifacts\n",
    "\n",
    "Azureml module support multiple module type:\n",
    "- Basic python module\n",
    "- Mpi module\n",
    "- Parallel run module\n",
    "- Hdi module (pending on backend support)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you need to configure your ws information here\n",
    "\n",
    "subscription_id = '74eccef0-4b8d-4f83-b5f9-fa100d155b22' #'4aaa645c-5ae2-4ae9-a17a-84b9023bc56a'#'74eccef0-4b8d-4f83-b5f9-fa100d155b22'\n",
    "workspace_name = 'lisal-amlservice' #'itp-pilot'#'kubeflow_ws_2' #'lisal-amlservice'\n",
    "resource_group = 'lisal-dev' #'itp-pilot-ResGrp'#'kubeflow-demo' #'lisal-dev'\n",
    "\n",
    "# Specify available aml compute in workspace\n",
    "pipeline_compute = 'always-on-ds2v2' #'k80-16-a'#'kubeflow-aks' #'always-on-ds2v2'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "# Configure your aml workspace \n",
    "\n",
    "!az login \n",
    "!az account set -s $subscription_id \n",
    "!az ml folder attach -w $workspace_name -g $resource_group \n",
    "\n",
    "# Configure global .amlignore, it's designed for register module from local development environment\n",
    "# !az configure --defaults module_amlignore_file=./.amlignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Register azureml modules from github url\n",
    "\n",
    "!az ml component create --file https://github.com/lisagreenview/hello-aml-modules/blob/master/train-score-eval/train.yaml --label default\n",
    "!az ml component create --file https://github.com/lisagreenview/hello-aml-modules/blob/master/train-score-eval/score.yaml --label default\n",
    "!az ml component create --file https://github.com/lisagreenview/hello-aml-modules/blob/master/train-score-eval/eval.yaml --label default\n",
    "!az ml component create --file https://github.com/lisagreenview/hello-aml-modules/blob/master/train-score-eval/compare2.yaml --label default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list available custom module in aml workspace\n",
    "!az ml component list -o table "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create pipeline\n",
    "You can build pipeline through SDK experience, or drag-n-drop way through [Designer](https://ml.azure.com/visualinterface?wsid=/subscriptions/74eccef0-4b8d-4f83-b5f9-fa100d155b22/resourcegroups/kubeflow-demo/workspaces/kubeflow_ws_1&flight=cm,nml,newGraphDetail,newGraphAuthoring,all&tid=72f988bf-86f1-41af-91ab-2d7cd011db47) in workspace portal\n",
    "\n",
    "The new SDK:\n",
    "* Symplified the syntax to provide consistent experience with drag-n-drop\n",
    "* Support intellisense and docstring, free you to work with dict all the time\n",
    "* Support creating a pipeline with unpublished module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from azureml.core import Workspace, Dataset\n",
    "from azure.ml.component import Component\n",
    "\n",
    "ws = Workspace.get(name=workspace_name, subscription_id=subscription_id, resource_group=resource_group)\n",
    "\n",
    "# get modules\n",
    "# load module from local unpublished module\n",
    "train_module_func = Component.load(ws, name='microsoft.com.azureml.samples.train')\n",
    "score_module_func = Component.load(ws, name='microsoft.com.azureml.samples.score')\n",
    "eval_module_func = Component.load(ws, name='microsoft.com.azureml.samples.evaluate')\n",
    "compare_module_func = Component.load(ws, name='microsoft.com.azureml.samples.compare_2_models')\n",
    "\n",
    "\"\"\"\n",
    "# load module from ws published modules\n",
    "train_module_func = Component.from_yaml(ws, yaml_file='./train-score-eval/train.yaml')\n",
    "score_module_func = Component.from_yaml(ws, yaml_file='./train-score-eval/score.yaml')\n",
    "eval_module_func = Component.from_yaml(ws, yaml_file='./train-score-eval/eval.yaml')\n",
    "compare_module_func = Component.from_yaml(ws, yaml_file='./train-score-eval/compare2.yaml')\n",
    "\"\"\"\n",
    "\n",
    "# get dataset\n",
    "training_data_name = 'training_data'\n",
    "test_data_name = 'test_data'\n",
    "\n",
    "if training_data_name not in ws.datasets:\n",
    "    print('Registering a training dataset for sample pipeline ...')\n",
    "    train_data = Dataset.File.from_files(path=['https://dprepdata.blob.core.windows.net/demo/Titanic.csv'])\n",
    "    train_data.register(workspace = ws, \n",
    "                              name = training_data_name, \n",
    "                              description = 'Training data (just for illustrative purpose)')\n",
    "    print('Registerd')\n",
    "else:\n",
    "    train_data = ws.datasets[training_data_name]\n",
    "    print('Training dataset found in workspace')\n",
    "\n",
    "if test_data_name not in ws.datasets:\n",
    "    print('Registering a test dataset for sample pipeline ...')\n",
    "    test_data = Dataset.File.from_files(path=['https://dprepdata.blob.core.windows.net/demo/Titanic.csv'])\n",
    "    test_data.register(workspace = ws, \n",
    "                          name = test_data_name, \n",
    "                          description = 'Test data (just for illustrative purpose)')\n",
    "    print('Registered')\n",
    "else:\n",
    "    test_data = ws.datasets[test_data_name]    \n",
    "    print('Test dataset found in workspace')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dsl pipeline \n",
    "* 'Pipeline parameter' is exposed as pipeline function input parameter\n",
    "* Pipeline output is the return of pipeline function\n",
    "\n",
    "### module function\n",
    "* module input can be set through set_inputs() or module initialization function\n",
    "* module parameter can be set through set_parameter() or module initialization function\n",
    "* module runsetting including compute, datastore, data mode and other runtime parameter are set through runsettings.configure()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ml.component import dsl\n",
    "\n",
    "# define a sub pipeline\n",
    "@dsl.pipeline(name = 'train-score-eval', \n",
    "              description = 'train model and evaluate model perf')\n",
    "def training_pipeline(input_data, test_data, learning_rate):\n",
    "    train = train_module_func()\n",
    "\n",
    "    train.set_inputs(training_data=input_data, learning_rate=learning_rate, max_epochs=5)\n",
    "\n",
    "    score = score_module_func(\n",
    "        model_input=train.outputs.model_output, \n",
    "        test_data=test_data)\n",
    "\n",
    "    eval = eval_module_func(scoring_result=score.outputs.score_output)\n",
    "    \n",
    "    return {'eval_output': eval.outputs.eval_output, 'model_output': train.outputs.model_output}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define pipeline with sub pipeline\n",
    "@dsl.pipeline(name = 'A dummy pipeline', \n",
    "              description = 'select best model trained with different learning rate',\n",
    "              default_compute_target = pipeline_compute)\n",
    "def dummy_automl_pipeline(input_data, test_data, learning_rate_1, learning_rate_2):\n",
    "    train_and_evalute_model1 = training_pipeline(input_data, test_data, learning_rate_1)\n",
    "    train_and_evalute_model2 = training_pipeline(input_data, test_data, learning_rate_2)\n",
    "    \n",
    "# create pipeline\n",
    "my_pipeline = dummy_automl_pipeline(input_data=train_data, test_data=test_data, learning_rate_1=0.01, learning_rate_2=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validate pipeline and visualize the graph\n",
    "my_pipeline.validate()"
   ]
  },
  {
   "source": [
    "### Submit a pipeline run"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save as a draft, then you can continue to modify the pipeline in AML Studio Designer page\n",
    "my_pipeline._save(experiment_name = 'pipeline-with-azureml-module')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pipeline parameter can be override when submit pipeline\n",
    "from azure.ml.component._version import VERSION\n",
    "\n",
    "run = my_pipeline.submit(experiment_name='pipeline-with-azureml-component', tags={'mode':'SDK/dsl','SDK-version':f'{VERSION}'}, pipeline_parameters={'input_data':train_data,'test_data':test_data, 'learning_rate_1': 0.05, 'learning_rate_2':0.06})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define pipeline with sub pipeline\n",
    "@dsl.pipeline(name = 'A dummy pipeline', \n",
    "              description = 'select best model trained with different learning rate',\n",
    "              default_compute_target = pipeline_compute)\n",
    "def dummy_automl_pipeline(input_data, test_data, learning_rate_1, learning_rate_2):\n",
    "    train_and_evalute_model1 = training_pipeline(input_data, test_data, learning_rate_1)\n",
    "    train_and_evalute_model2 = training_pipeline(input_data, test_data, learning_rate_2)\n",
    "    \n",
    "    compare = compare_module_func(\n",
    "        model1=train_and_evalute_model1.outputs.model_output, \n",
    "        eval_result1=train_and_evalute_model1.outputs.eval_output,\n",
    "        model2=train_and_evalute_model2.outputs.model_output,\n",
    "        eval_result2=train_and_evalute_model2.outputs.eval_output\n",
    "    )\n",
    "\n",
    "    return {'best_model': compare.outputs.best_model, 'best_result': compare.outputs.best_result}\n",
    "\n",
    "# create pipeline\n",
    "my_pipeline_2 = dummy_automl_pipeline(input_data=train_data, test_data=test_data, learning_rate_1=0.25, learning_rate_2=0.15)\n",
    "run = my_pipeline_2.submit(experiment_name='pipeline-with-azureml-component', tags={'mode':'SDK/dsl','SDK-version':f'{VERSION}'})\n",
    "run.wait_for_completion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_pipeline.diff(my_pipeline_2)"
   ]
  },
  {
   "source": [
    "### Publish and consume pipeline endpoint"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ml.component._endpoint import PipelineEndpoint\n",
    "\n",
    "# publish pipeline endpoint\n",
    "pipeline_endpoint = PipelineEndpoint.publish(workspace=ws, name=\"Train-Score-Eval-Compare\",\n",
    "                                             pipeline=my_pipeline_2, description=\"Train-Score-Eval-Compare\", \n",
    "                                             set_as_default=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get pipeline endpoint by name\n",
    "my_pipeline_endpoint = PipelineEndpoint.get(workspace=ws, name=\"Train-Score-Eval-Compare\")\n",
    "\n",
    "# trigger published pipeline, assign value to pipeline parameter\n",
    "run_pipeline_endpoint = my_pipeline_endpoint.submit(experiment_name=\"PipelineEndpoint-Train-Score-Eval-Compare\", pipeline_parameters={'input_data':test_data,'test_data':train_data, 'learning_rate_1':0.03, 'learning_rate_2':0.04})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export pipeline yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipeline.export(directory=os.path.join('.', 'export'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load an unpublished module, and test if locally\n",
    "* Support load module from local or github \n",
    "* Support use the module without publish it to aml ws\n",
    "* Use module.run() to test the module locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from azure.ml.component import Component\n",
    "\n",
    "# load unregistered module from github\n",
    "compare_2_func = Component.from_yaml(ws, yaml_file='https://github.com/lisagreenview/hello-aml-modules/blob/master/train-score-eval/compare2.yaml')\n",
    "help(compare_2_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "# create a module\n",
    "# you need to prepare local test data to initialize the module\n",
    "compare = compare_2_func(model1 = 'D:\\\\work\\\\code\\\\train-score-eval\\\\compare\\\\data\\\\compare_entry\\\\inputs\\\\model1',\n",
    "                         eval_result1 = 'D:\\\\work\\\\code\\\\train-score-eval\\\\compare\\\\data\\\\compare_entry\\\\inputs\\\\eval_result1',\n",
    "                         model2 = 'D:\\\\work\\\\code\\\\train-score-eval\\\\compare\\\\data\\\\compare_entry\\\\inputs\\\\model2',\n",
    "                         eval_result2 = 'D:\\\\work\\\\code\\\\train-score-eval\\\\compare\\data\\\\compare_entry\\\\inputs\\\\eval_result2')\n",
    "\n",
    "compare.run(use_docker=True, track_run_history=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a new pipeline with unregistered module\n",
    "\n",
    "new pipeline = dummy_automl_pipeline + copy_file_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline(name='pipeline-with-azureml-module',default_compute_target = pipeline_compute)\n",
    "def add_copy_file():\n",
    "    compare_pipeline = dummy_automl_pipeline(input_data=train_data, test_data=test_data)\n",
    "    copy_file_node = copy_file_func(input_folder=compare_pipeline.outputs.best_result)\n",
    "    copy_file_node.runsettings.configure(node_count=1)\n",
    "\n",
    "    return {**copy_file_node.outputs}\n",
    "\n",
    "new_pipeline = add_copy_file()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run pipeline locally\n",
    "\n",
    "* pipeline.run() support BasicPythonModule, ParallelRunModule and MpiModule \n",
    "* Local run and module node log will be uploaded and recorded in aml ws, and the running status will also be synced back to aml ws\n",
    "* For mpi module, local run only support image with openmpi, intelmpi not support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "run = new_pipeline.run(experiment_name = 'pipeline-local_run', show_output = True, show_graph = True)\n",
    "run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# submit to aml ws\n",
    "run = new_pipeline.submit(experiment_name='pipeline-with-azureml-module', tags={'mode':'module-SDK','SDK-version':f'{CLI_SDK_VERSION}'}, description='add parallel copy file module')\n",
    "run.wait_for_completion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.10 64-bit ('amlmodule': conda)",
   "language": "python",
   "name": "python361064bitamlmoduleconda94216afc072640efa4ed7a053209d802"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}